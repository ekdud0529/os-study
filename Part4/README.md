## 김다영

### 9장

### 기준 레지스터와 상한 레지스터란?
> 기준 레지스터는 가장 작은 물리 메모리 주소를 저장하고, 상한 레지스터는 사용할 수 있는 영역의 크기를 저장하는 레지스터 입니다.
> 프로세스가 사용 가능한 영역에만 접근할 수 있도록 사용합니다.

### 주소 할당 (Address Binding)이란?
> 데이터를 물리 메모리의 어느 부분에 적재할지 결정하는 것입니다.
> 바인딩 작업은 컴파일, 로딩, 실행 시간에 발생할 수 있습니다. 

### 가상 주소란?
> 실행 시간 바인딩을 한 경우 논리주소와 물리 주소가 다르다.
> 이 경우 논리 주소를 가상 주소라고 한다.

### 메모리 관리 장치(MMU)란?
> 논리 주소를 물리 주소로 변환해주는 하드웨어 장치입니다.

### 동적 적재란?
> 프로세스의 필요한 루틴이 호출될 때, 해당 루틴을 메모리에 적재하는 방식입니다.

### 동적 로딩하는 3가지 방법
> 첫 번째로 사용 가능한 가용 공간을 할당하는 최초 적합과 
> 사용 가능한 공간 중 가장 작은 것을 할당하는 최적 적합, 
> 가장 큰 가용 공간을 할당하는 최악 적합 방법이 있습니다.
> 최초, 최적 적합 모두 시간과 메모리 효율이 최악 적합보다 좋습니다.

### 연속적인 메모리 할당으로 발생하는 문제는?
### 외부 단편화란?
> 프로세스가 메모리에 적재되고, 제거되는 일이 반복될 때, 일부 너무 작은 크기의 가용 공간이 발생하는 문제입니다. 모두 합하면 충분한 공간이 되지만, 여러 공간에 분산되어 프로세스를 할당할 수 없게 됩니다. 

### 내부 단편화란?
> 프로세스에게 할당된 공간이 요구된 공간보다 클 수 있습니다. 이 때 남은 공간이 낭비되는 것을 내부 단편화라고 합니다.

### 페이징이란?
> 프로세스를 페이지 단위로 나누어 분산해서 메인 메모리의 프레임에 적재되는 방식입니다.
> 논리 주소의 페이지 번호를 통해 페이지 테이블에 접근하여, 물리 메모리의 프레임 주소를 찾고, 페이지 오프셋 값을 결합해 물리 메모리 주소를 찾아 사용합니다.


### 페이징에서 프레임을 할당하는 방법
1. 프로세스가 실행되기 위해 도착 시, 프로세스 크기가 페이지 몇 개에 해당하는지 조사한다.
2. 필요한 만큼 사용할 수 있다면, 해당 프로세스에 프레임을 할당한다.
3. 해당 프레임 번호를 페이지 테이블에 기록한다.
4. 페이지 마다 위 과정을 반복한다.

### TLB란?
> 참조했던 페이지를 담아주는 캐시 역할을 해 메모리 접근 시간을 줄여줍니다.

### 공유 페이지란?
> 실행 주에는 절대 변하지 않는 재진입 코드를 공유해 필요한 공간을 절약할 수 있습니다.

### 계층적 페이징이란?
> 현대 컴퓨터에서 사용하는 페이지 테이블이 매우 큽니다. 모든 페이지 테이블을 메인 메모리에 연속적으로 할당하기 어렵기 때문에 페이지 테이블 자체를 다시 페이징해서 해결하는 방법입니다.

### 스와핑이란?
> 프로세스나 프로세스의 일부분이 실행 중 임시로 백업 저장장치로 내보냈다가, 실행을 계속하기 위해 메모리로 들여보내는 방법입니다.
> 물리 메모리 크기가 충분하지 않아도 스와핑을 통해 프로세스를 동시 실행할 수 있어 멀티 프로그래밍 정도를 높일 수 있습니다.

### 10장

### 가상 메모리란?
> 실제 물리 메모리 개념과 논리 메모리 개념을 분리한 것으로, 물리 메모리의 크기에 제약 받지 않을 수 있습니다.

### 가상 메모리 이점?
1. 프로그램이 물리 메모리보다 클 수 있다.
2. 프로그램이 더 작은 메모리를 사용하므로, 더 많은 프로그램을 동시에 수행할 수 있다.
3. 스와핑 시간이 줄어들어, 프로그램 실행시간이 빨라진다.

### 요구 페이징이란?
> 프로그램 실행 중 필요할 때만 페이지를 적재하는 기법입니다.
> 필요한 프로그램의 일부만 적재하기 때문에 메모리를 더 효율적으로 사용할 수 있습니다.

### 페이지 폴트란?
> 아직 메모리에 적재되지 않은 페이지에 접근 요청을 한 것입니다.

### 페이지 교체란?
> 페이지 폴트가 발생했을 때 가용 프레임이 없는 경우, 현재 사용되지 않는 프레임을 찾아 해당 프레임을 비워 사용하는 방법입니다.
> 페이지 교체 알고리즘을 통해 희생자를 선정해 제거합니다.

### 균등 할당 (Equal Allocation) 알고리즘
> 모두에게 같은 몫의 프레임을 주는 알고리즘이다.
> 운영체제가 사용해야 하는 프레임은 제외된다.

### 비례 할당 (Proportional Allocation) 알고리즘
> 가용 메모리를 각 프로세스의 크기 비율에 맞춰 할당하는 알고리즘이다.

### 전역 교체 (Global Replacement) 알고리즘
> 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임을 대상으로 찾는 알고리즘이다.

### 지역 교체(Local Replacement) 알고리즘
> 각 프로세스가 자기에게 할당된 프레임 중에서만 교체될 희생자를 선택하는 알고리즘이다.

### 스래싱이란?
> 페이지 폴트가 발생해 페이지를 교체할 때, 이미 활발하게 사용되는 페이지들로만 이루어져 바로바로 반복해서 페이지 폴트가 발생할 수 있는데 이처럼 과도한 페이징 작업을 스래싱이라고 합니다.


## 조예은
## 조민서
# Part 4. 메모리 관리

### 컴퓨터는 2^64 bit 주소 공간을 가진 시스템에서 페이지의 크기가 1 KB라면 페이지 테이블은 몇 개를 가지나요?

- 64-10 = 약 2^54개의 항목

### 논리주소와 물리주소에 대해 설명해 주세요.

### **1. 논리 주소 Logical Address== Virtual Address**

논리 주소는 CPU에 의해 프로그램이 실행되고 있을 때 만들어진다. 물리적으로 존재하는 주소가 아니라 개념적으로 존재하는 주소이므로 가상 주소Virtual Address라고도 부른다. 논리 주소/가상 주소는 CPU에 위치한 메모리의 물리적 주소를 가르킨다.

Memory-Management Unit, MMU라는 하드웨어 장치는 논리 주소와 대응되는 물리 주소를 연결mapping한다.

Logical Address Space라는 용어는 프로그램에 의해서 만들어진 모든 논리 주소의 집합이다.

### **2. 물리 주소 Physical Address**

물리 주소는 메모리 상의 물리적인 주소를 의미한다.

사용자들은 직접적으로 물리 주소로 접근하지 못하고 대신 대응되는 논리 주소로 접근한다. 프로그램들은 논리 주소를 생성하고 해당 프로그램이 이 논리 주소에서 실행되고 있다고 상정한다. 그러나 프로그램이 실행되기 위해서는 물리 주소가 필요하다. 그러므로 MMU가 논리 주소가 사용되기 전에 논리 주소와 물리 주소를 대응mapping시킨다.

Physical Address Space라는 용어는 Logical Address Space와 대응되는 물리 주소의 집합이다.

### MMU(메모리 관리 장치)에 대해 설명해 주세요.

**MMU란 CPU코어 안에 탑재되어 가상 주소를 실제 메모리 주소로 변환해주는 장치**입니다.

### 동적 적재(dynamic loading)에 대해 설명해 주세요.

프로세스가 시작될 때 프로세스 주소 공간 전체를 메모리에 올려놓는 것이 아니라 메모리를 좀 더 효율적으로 사용하기 위해 필요한 루틴이 호출될 때 해당 루틴을 메모리에 적재하는 방식을 말합니다.

즉, 필요한 시점에만 올리니까 메모리를 더 효율적으로 쓰이는게 가능하다.

### 가상 메모리 (Virtual Mememory)

가상 메모리란 실제 메모리 크기와 관계 없이 메모리를 사용할 수 있도록 가상 메모리 주소를 사용하는 것을 뜻한다. 프로세스의 일부분만 메모리에 로드하고 나머지는 보조 기억 장치(가상 메모리 공간)에 로드한다.

- MMU를 통해 논리 주소, 물리 주소를 나누어 사용하여 CPU를 속인다.
- MMU = 가상 주소를 실제 메모리 주소로 변환해주는 장치

**장점**

- 실제 메모리 (RAM) 보다 더 큰 공간을 사용
- 가상의 주소를 사용해 논리적인 연속성을 제공
- 물리 메모리의 주소 공간을 몰라도 됨

### 어떤 메모리에 위치한 변수에 접근하기 위해서는 먼저 페이지 테이블에 있는 메모리를 먼저 접근해서 페이지 테이블 데이터를 가지고 온 후 이것을 참조해서 논리 주소를 물리 주소로 변환하는 작업을 거친 후에 실제로 그 메모리에 접근하여 두 번 메모리에 접근하는 상황이 발생하게 된다. 이 문제를 어떻게 해결하나요?

![image](https://user-images.githubusercontent.com/64322765/217247763-cc4dbade-fd77-472e-98c2-4e14c18480cc.png)

**메모리 접근 시간 문제**

그래서 실질적으로 어떤 메모리에 위치한 변수에 접근하기 위해서는 먼저 이 페이지 테이블이 있는 메모리를 먼저 접근해서 페이지 테이블 데이터를 가지고 온 후 이것을 참조해서 논리 주소를 물리 주소로 변환하는 작업을 거친 후에 실제로 그 메모리에 접근하여 2번 메모리에 접근하는 상황이 발생하게 된다. 이는 페이징 성능상에 중요한 문제가 된다.

**TLB (Translation Look aside Buffer)**

이러한 문제를 해결하기 위한 방법으로 페이지 테이블을 위한 소형의 하드웨어 캐시가 있다

어쨌든 두 번 메모리에 접근해야 하지만 페이지 테이블을 읽는 속도 만큼은 매우 빠르게 한다는 것이 페이지 테이블 캐싱의 원리이다. 그리고 MMU는 이런 페이지 테이블 캐싱을 위해서 컴퓨터 시스템에 있는 캐시 메모리를 그대로 이용하는 것이 아니고 MMU내에 TLB라고 하는 페이지 테이블만 전용으로 캐싱하는 별도의 캐시 메모리를 두게 된다.

- 접근 속도가 매우 빠른 연관 메모리 (associative memory)
- TLB 내의 각 항목(entry)은 키(key)와 값(value)로 구성되며 key는 페이지 번호, value는 페이지 번호에 해당하는 프레임 번호이다.
- 전체적으로 MMU 하드웨어가 주소 변환을 하는 과정을 살펴보자면 CPU가 메모리를 참조하기 위해서 그 데이터의 논리 주소를 꺼내게 될 것이다. 그러면 이 논리 주소 중에서 페이지 번호에 해당하는 부분을 가지고서 페이지 테이블 참조를 할 텐데 이 때는 일단 TLB를 먼저 참조하게 된다. 그런데 TLB는 페이지 테이블의 일부만 갖고 있기 때문에 인덱스를 바로 참조하는 것이 아니고 내가 가지고 있는 페이지 번호가 TLB안에 있는지를 검색을 해야 한다. 그리고 검색한 결과 해당 페이지 번호가 있다면 프레임 번호를 얻어내어 물리 주소를 형성하게 되는 것이다. 이렇게 되면 빠른 속도로 프레임 번호를 얻을 수 있다.(TLB hit) 하지만 원하는 페이지 번호가 없다면 이는 TLB miss라고 하는 것이고 이렇게 되면 어쩔 수 없이 TLB 참조 후에 메모리 안에 저장되어 있던page table도 참조를 해야 한다. 그래서 이렇게 TLB miss가 나게되면 TLB가 없을 때보다 더 긴 시간이 걸리게 된다. 따라서 이 시스템이 원할하게 잘 동작 하려면 TLB에서 내가 원하는 페이지를 찾을 확률이 매우 높아야만 한다.

### 최초 적합(first-fit), 최적 적합(best-fit), 최악 적합(worst-fit)에 대해 설명해 주세요.

- 최초 적합: 첫 번째 사용 가능한 가용 공간을 할당한다. 검색은 집합의 시작 또는 지난번 검색이 끝난 곳에서 시작 될 수 있습니다.
- 최적 적합: 사용 가능한 공간 정에서 가장 작은 것을 선택한다. 리스트가 크기순으로 정렬 되어 있지 않다면 모든 리스트를 검색 해야 하지만 이 방법은 아주 작은 가용 공간을 만듭니다.
- 최악 적합: 가장 큰 가용 공간을 선택한다. 할당해 주고 남은 가용공간은 충분히 커서 다른 프로세스들이 유용하게 사용될 수 있다. 이때 가용공간들이 크기 순으로 정렬되어 있지 않으면 모든 리스트를 다 검색해야 합니다.

### 내부 단편화(internal fragmentation)와 외부 단편화(external fragmentaion)에 대해 설명해 주세요.

**내부 단편화**: 1000B 크기의 가용공간에서 990B를 요구하는 프로세스가 있으면 시스템은 10B의 가용공간 만큼 더 큰 부담을 가지게 된다.
 따라서 일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수배로 해주는 것이 보통이다. 이 경우 할당된 공간은 요구된 공간보다 약간 더 클 수 있다. 이들 두 크기 사이의 남는 부분이 내부 단편화다.

**외부 단편화:** 프로세스들이 메모리에 적재되고 제거되는 일이 반복되면, 어떤 가용공간은 아주 작은 공간이 됩니다. 이처럼 유휴공간들을 모두 합치면 충분한 공간이 되지만 그것들이 아주 작은 공간들로 분산되어 있을때 외부 단편화가 발생합니다.
- 최초 적합, 최적 적합 전략 모두 외부 단편화로 인해 어려움을 겪는데 단편화 크기에 따라 어느 전략을 사용할지 결정 합니다.
- 외부 단편화를 해결하는 방법으로 압축, 페이징 방법이 있습니다.
    
    압축: 모든 메모리 내용을 한군데로 몰고 모든 가용공간을 가른 한군데로 몰아서 큰 블록을 만듭니다.   
    압축은 항상 가능한것이 아니고, 프로세스들의 재배치가 실행시간에 동적으로 이루어지는 경우에만 가능합니다. 압축은 보통 비용이 많이 듭니다.

    페이징: 한 프로세스의 논리주소공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용되는 경우 물리메모리를 프로세스에 할당하는 방법입니다.
    

### 단편화 해결방법

### 페이징(Paging)기법 - 가상 메모리 사용, 외부 단편화 해결, 내부 단편화 존재

가상메모리를 같은 크기의 블록으로 나눈 것을 페이지라고 하고 RAM을 페이지와 같은 크기의 블록으로 나눈 것을 프레임이라고 한다. 페이징 기법이란 사용하지 않는 프레임을 페이지로 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 방법을 말한다. 페이지와 프레임을 대응시키기 위해 page mapping과정이 필요해서 paging table을 만든다. 페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 **외부 단편화 문제를 해결**할 수 있다. 그러나 페이지 단위를 작게하면 외부 단편화 문제를 해결할 수 있지만 그 대신 **page mapping과정이 많아져 효율이 떨어지게 된다**.

### **세그멘테이션(Segmentation)기법 - 가상메모리사용, 내부 단편화 해결, 외부 단편화 존재**

페이징기법에서 가상메모리를 같은 크기의 단위로 분할했지만 세그멘테이션기법에서는 가상메모리를 서로 크기가 다른 논리적 단위의 세그먼트로 분할한 후 메모리를 할당하여 실제 메모리 주소로 변환을 하게 된다. 각 세그먼트는 연속적인 공간에 저장되어 있다. 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아 할당하는 기법이다. 페이징 기법과 마찬가지로 mapping을 위해 세그먼트 테이블이 필요하다. **프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부단편화는 일어나지 않으나**여전히 중간에 프로세스가 메모리를 해제하면 생기는 틈, 즉 **외부 단편화 문제는 해결되지 못한다**.

### 메모리 풀(Memory Pool)기법

### 64비트 논리 주소 공간을 가진 시스템에서 계층적 페이징(Hierachical Paging) 기법이 부적합한 이유를 설명해주세요.

- 페이징 기법은 모든 페이지 테이블을 메인 메모리에서 연속적으로 할당하지 않기 위해 사용하는 기법 입니다.
- 64비트 논리 주소 공간을 가진 시스템에서 우선 각 페이지의 크기가 4KB 라고 가정하고, 페이징 테이블을 만들면
- 2^64 / 2^12 → 64-12 즉 2^52개의 페이지 테이블을 가진다. 2단계 페이징 기법을 이용하면  안쪽 페이지 테이블은 1페이지가 되는데, 여기서는 2^10개의 4B(byte) 짜리 항목을 가진다. 바깥 페이지 테이블은 2^42개의 페이지 테이블을 가지고 2^44 B로 구성된다. 2^42B*4B
- 즉 바깥 테이블은 2^44B의 크기를 요구한다.
- 이와 같은 방식으로
    
    3단계 32 10 10 12
    
    4단계 22 10 10 10 1 
    
    5단계 12 10 10 10 10 12와 같이 여러 개의 바깥 페이지가 필요하다. 각 논리 주소를 사상하기 위해 너무 많은 메모리 접근을 필요로 하기 때문에 비현실 적이다. 
    
    그래서 64비트 컴퓨터는 가상주소를 해시로 사용하는 해시 페이지 테이블 또는 해시 페이지 테이블과 비슷한 클러스터 페이지 테이블을 사용합니다.
    
    - 해시테이블과 클러스터 테이블 차이점
        
        **해시 페이지 테이블**의 각 항목이 한 개의 페이지만 가리키는 것에 반해 **클러스터 페이지 테이블**의 각 항목은 여러(예를 들면 16개) 페이지를 가리킵니다.
        
         따라서 한 개의 페이지 테이블 항목이 여러 페이지 프레임에 대한 변환 정보를 지닐 수 있습니다. 클러스터 페이지 테이블은 **성간(**sparse, 메인 메모리에서 stack영역과 heap영역 사이에 비어있는 메모리) 주소 공간에 유용하게 사용됩니다. 
        
        즉 클러스터 페이지 테이블은 메모리 액세스가 비연속적이면서 전 주소 공간으로 넓게 퍼져 나오는 경우에 유용합니다
        
    - 성간?(sparse 주소 공간이 도대체 뭐야?)
         
         ![image](https://user-images.githubusercontent.com/64322765/217248216-7bc0ba5a-8c48-41a0-aabf-79f65d741e78.png)

        
    

**하지만 32비트 라면?**
각 페이지의 크기가 4KB라면 12비트 오프셋과
20비트짜리 페이지 번호로 나뉘는데, 2단계 페이징을 하면 10비트 페이지테이블 10비트짜리 페이지 오프셋으로 나뉜다. 

![image](https://user-images.githubusercontent.com/64322765/217247567-6f9ccbc4-c79f-4b67-8bbc-c97a7d732acb.png)

- 즉 계층적 페이징 기법은 32비트 시스템을 위한 기법이다.

### **해시 페이지 테이블 (Hashed Page Table)**

- 논리 주소의 페이지 번호를 해시 값으로 사용
- 32비트 이상의 논리 주소 공간을 위한 페이지 테이블 구성방법
- 같은 위치에 해당되는 해시 페이지 테이블의 항목은 연결 리스트 구성 - 페이지 번호, 프레임 번호, 다음 원소 포인터

### **역 페이지 테이블 (Inverted Page Table)**

**물리 메모리의 프레임 번호로 인덱스되는 테이블**

원래 페이지 테이블에서는 프로세스의 논리 주소를 인덱스로 하고 어떤 해싱을 해서 실제 메모리의 프레임 주소로 바꿔준다. 이때 논리 주소 공간의 관점에서 보면 실제 프로세스가 사용하지 않는 것들에 대해서도 페이지 테이블 엔트리를 유지하기 때문에 이 공간의 낭비가 생기게 된다. 하지만 반대로 메모리(RAM)의 관점에서 보면 RAM의 모든 위치들은 어떤 순간 어느 한 프로세스에 할당된 것이다. 그래서 논리 주소를 물리 주소로 바꿔주는 방식의 테이블이 아닌 반대로 물리 주소를 논리 주소로 바꿔주는 테이블을 만드는 것이 바로 역페이지 테이블이다.

**주소 변환**

논리주소: 프로세스 ID, 페이지 번호, 오프셋

프로세스 ID와 페이지 번호로 페이지 테이블을 검색 (search)

발견된 항목의 인덱스가 프레임 번호

**역 페이지 테이블의 특징**

작은 메모리 공간 필요하고 주소 변환 시간이 길어진다 (검색비용) -> 해시 테이블의 사용을 요구한다. 또한 메모리 공유가 어렵다.

### 모든 프로세스의 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리보다 큰 경우 OS는 어떻게 해결하나요? (스와핑)

- 프로세스가 실행되려면 메모리에 있어야 하는데, 그래서 프로세스가 스와핑(swapping)을 해야 합니다. 스와핑이란  프로세스의 일부분이 현재 메모리에서 잠깐 다른 저장 공간(HDD나 SSD 등 백업 장치)으로 내보내졌다가 다시 메모리로 돌아올 수 있는 개념입니다.
- 이렇게 하면 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리보다 큰 경우에도 스와핑을 이용하면  프로세스를 동시에 실행하는 것이 가능합니다 스와핑의 적합한 후보는 유휴(idle) 또는 대부분의 시간을 유휴상태로 보낸 프로세스가 스와핑에 적합한 후보입니다.
- 스와핑의 적합한 후보는 유휴(idle) 또는 대부분의 시간을 유휴상태로 보낸 프로세스가 스와핑에 적합한 후보입니다.
- 하지만 (표준스와핑)메모리와 백업저장장치 간에 프로세스전체를 이동하는데 걸리는 시간이 엄청나기 때문에 일반적으로 최신 os에서는 사용하지 않음. → 프로세스를 스와핑 하는게 아니라 페이지를 스와핑함, 이 과정을 페이징 이라고함.

# Part 5. 가상 메모리

### 요구 페이징(demand paging)에 대해 설명해 주세요.

- 요구 페이징의 기본 개념은 필요할 때만 페이지를 메모리에 적재하는 것 입니다.
- 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조저장장치에 있습니다. 따라서 이 둘을 구별하기 위해서 유효•무효(valid-invalid)비트 기법이 사용될 수 있습니다.

### 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 어떤 일이 발생하나요?

- 페이지 테이블 항목이 무효로 설정되어 있으므로 페이지 폴트 트랩(page-fault trap)을 발생 시킵니다.

### 페이지 폴트를 처리하는 과정을 설명해 주세요.

![image](https://user-images.githubusercontent.com/64322765/217246750-b80d62ec-3532-45ef-8654-8b31fa80f5d7.png)

1. 프로세스에 대한 내부 테이블(internal table)[일반적으로 프로세스 제어 블록 (PCB)과 함께 유지]을 검사해서 그 메모리 참조(reference)가 유효•무효인지를 알아낸다.
2. 만약 무효한 페이지에 대한 참조라면 그 프로세스는 중단된다. 만약 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 그것을 보조저장장치로부터 가져 와야 한다.
3. 빈 공간, 즉 가용 프레임(free frame)을 찾는다(예를 들면, 페이지 프레임 리스트 에서 하나를 가져옴). 빈 프레임이 있다면 바로 할당이 가능하지만 꽉 차있다면 이제 page replacement에 대한 고려를 해야 한다.
4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위 해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다. 이제 프로세스는 마치 그 페이지 가 항상 메모리에 있었던 것처럼 해당 페이지에 접근할 수 있다.

**정리하자면**

페이지를 참조하여 CPU가 연산을 하기위해 페이지 테이블에 접근하는데 해당 페이지가 무효 하다면 트랩이 걸려 OS가 CPU 제어를 하게 되고 보조저장장치에서 해당 페이지를 물리적 메모리에 올립니다.

하지만 보조저장장치**에 접근하는 것은 시간적 오버헤드가 무척 크기 때문에 페이지 폴트 비율을 낮추는 것이 중요합니다.**

표준 스와핑을 사용하여 프로세스를 스왑아웃하여 모든 프레임(물리 메모리)을 비우고 다중프로그래밍 정도를 줄 일 수 있지만, 메모리와 스왑공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분 os는 표준 스와핑을 사용하지 않는다.

순구 요구 페이징: 어떤 페이지가 필요해지기 전에는 결코 그 페이지를 메모리에 적재하지 않는 방법

### 쓰기 시 복사(copy-on-write) 방식에 대해 설명해 주세요.

fork를 하면 부모 프로세스의 페이지들을 실제로 자식 프로세스에 복사해 줌으로써 자식 프로세스의 주소 공간을 구성해 줍니다. 

하지만 대부분의 자식 프로세들은 exec 시스템 콜을 하는데, 이러면 부모로부터 복사해온 페이지들이 다 쓸모 없어집니다. 

그래서 부모의 페이지들을 다 복사해오는 대신 쓰기 시 복사(copy-on-write) 방식을 사용할 수 있습니다.

![image](https://user-images.githubusercontent.com/64322765/217247114-1e99ad4d-34f9-46f8-a3d9-2b5c1ded22a5.png)

위 두개의 그림을 보자 자식 프로세스가 시작할 때 부모 페이지를 당분간 함께 사용합니다. 

운영체제는 가용 프레임 리스트에서 프레임을 얻고 이 페이지의 복사본을 만들어서 자식 프로세스의 주소 공간에 사상시킨다. 따라서 자식은 그 개인용으로 따로 만 들어준 페이지에(부모와 공유하는 페이지가 아닌) 수정을 가하게 되는 것이다. 

이렇게 하면 프로세스가 수정을 하는 페이지들에 대해서만 복사본이 생기게 된다. 수정되지 않은 페이지들은 자식과 부모 간에 계속 공유될 수 있는 것이다.

### fork()와 vfork() 차이점을 말해주세요.

초록색 글씨 = fork()

주황색 글씨 = vfork()

fork와 vfork의 주된 차이점은 fork에 의해 생성 된 자식 프로세스가 부모 프로세스와는 별도의 메모리 공간을 가지고 있다는 것입니다.

그러나 **vfork** 시스템 호출로 작성된 자식 프로세스는 부모 프로세스**와 동일한 주소 공간**을 공유합니다.

fork를 사용하여 생성된 자식 프로세스는 부모 프로세스와 동시에 실행됩니다.

반면, vfork를 이용하여 생성된 자식 프로세스는 실행이 완료될 때까지 부모 프로세스의 실행을 일시 중단합니다.

fork는 부모와 자식 프로세스의 메모리 공간이 다른 프로세스에 의해 수행된 별도의 수정이므로 다른 페이지에 영향을 미치지 않습니다. 

반면, vfork는 부모와 자식 프로세스가 메모리 공간이 동일한 프로세스에 의해 수행된 같은 메모리의 주소 수정이므로 다른 페이지에 영향을 미칩니다.

fork는 대안으로 **copy-on-write** 를 사용하여 부모와 자식 프로세스가 페이지를 수정하기 전까지 동일한 주소 공간을 공유하게 합니다. 

반면, vfork는 copy-on-write를 사용하지 않습니다. 그래서 vfork를 통한 자식이 부모 주소 공간의 페이지를 수정하게 되면 변경된 페이지가 재 실행 시 부모 프로세스가 그대로 보입니다. 따라서 vfork를 사용할 때에는 자식이 부모 주소 공간의 페이지를 변경하지 않도록 주의해야 합니다.

- fork:
    
    부모와 자식간의 별도의 독립된 메모리공간
    
    부모와 자식 동시 실행
    
    수정시 별도의 수정으로 다른 페이지에 영향X
    
    copy-on-write사용O
    
- vfork:
    
    부모와 자식간의 같은 메모리 공간
    
    자식 실행시 부모는 블로킹됨(경생상황 방지)
    
    자식 수정시 부모와 같은 메모리주소 수정으로 다른 페이지에 영향O
    
    copy-on-write사용X
    

### 메모리 초과 할당이 일어나는 과정 그리고 해결 방안

1. 프로세스가 실행되는 동안 페이지 폴트 발생
2. os는 보조저장장치에 저장된 페이지 위치를 찾지만 물리 메모리에 들어갈 자리가 없음을 인지.
3. 
    
    1. 프로세스 종료하는 방법이 있지만, 시스템의 활용률과 처리율 관점에서 좋은 방법이 아님.
    
    2. 또한 표준 스와핑을 사용하여 프로세스를 스왑아웃하여 모든 프레임(물리 메모리)를 비우고 다중프로그래밍 정도를 줄 일 수 있지만, 메모리와 스왑 공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분 os는 표준 스와핑을 사용하지 않는다.
    
    3 .스와핑과 페이지 교체를 결합한다.
    

페이지 교체 알고리즘은 page-fault 발생 비율을 줄이는 것을 목표로 한다.

### **페이지 교체 알고리즘의 종류**

1. **OPT** - Optimal : 앞으로 가장 오랫동안 사용되지 않을 페이지 교체
2. **FIFO** - First In First Out
3. **LRU** - Least ***Recently*** Used : 가장 오랫동안 사용되지 않은 페이지 교체
4. **LFU** - Least ***Frequently*** Used : 참조 횟수가 가장 작은 페이지 교체
5. **MFU** - Most Frequently used : 참조 횟수가 가장 많은 페이지 교체
6. **NUR** - Not Used Recently : 최근에 사용하지 않은 페이지 교체

### OPT (Optimal Page Replacement) - 최적 페이지 교체

OPT 알고리즘은 앞으로 가장 사용하지 않을 페이지를 가장 우선적으로 내려 보내는 알고리즘이다. FIFO에 비해서 페이지 결함이 일어날 횟수가 더 적다. 하지만 OPT의 경우 앞으로도 사용이 잘 되지 않을 것이라는 보장이 없으므로 미래를 알 수 없기 때문에 실질적으로 수행하기에는 큰 어려움이 있다고 할 수 있다.

### FIFO (First-in First Out)

메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘이다. 따라서 victim page의 대상은 가장 먼저 메모리에 올라온 페이지가 되는 것이다. 이 방법은 가장 간단한 방법이다. 특히 초기화 코드에 대해서 적절한 방법이라고 할 수 있다. 초기화 코드는 처음에 프로세스가 실행될 때 최초 초기화를 시키는 역할만 진행하고 다른 역할은 수행하지 않기 때문에 메인 메모리에서 내려 보내도 괜찮다. 하지만 처음에 프로세스를 실행시키는 데에 무조건 필요하다. 따라서 FIFO의 방법을 사용하면 초기화 시켜준 후 가장 먼저 내려 보내지게 된다. FIFO 알고리즘은 프레임의 수가 적을수록 페이지 결함이 더 많이 일어나게 된다. 계속 교체를 해주어야 하기 때문이다. 하지만 프레임의 수가 많아질수록 페이지 결함의 횟수는 감소하게 된다.

**Belady's Anomaly 이란?**

- 간단히 말해서 페이지 교체 알고리즘 중의 하나인 FIFO(First In First Out)에서, 원래 페이지 프레임의 개수를 늘리면 page fault발생이 감소 해야 하나, 오히려 늘어나는 경우가 발생하는데 그것을 Belady's Anomaly라 한다.

### LRU (Least-Recently-Used)

LRU 알고리즘은 최근에 사용하지 않은 페이지를 가장 먼저 내려 보내는 알고리즘이다. 최근에 사용되지 않으면 나중에도 사용되지 않을 것이라는 아이디어로부터 온 것이다. OPT의 경우에는 미래에 대한 예측이지만 LRU의 경우에는 과거를 보고 판단하므로 실질적으로 사용 가능한 알고리즘이라고 할 수 있다. 실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다고 할 수 있따. 비록 OPT보다는 페이지 결함이 더 일어날 수 있지만 실제로 사용할 수 있는 알고리즘 중에서는 좋은 방법 중 하나라고 할 수 있다.

![image](https://user-images.githubusercontent.com/64322765/217247221-c1745f78-9932-4846-b424-701e8d19daf2.png)

### 여러 개의 프로세스들에 제한된 가용 메모리를 어떻게 할당할 것인가?

**균등 할당(equal allocation):** 100개의 프레임이 있으면 2개의 프로세스에 50개씩 할당해준다.

**비례 할당(proportional allocation):**  프로세스1이 프로세스2보다 메모리 사용량이 많으면 프로세스1에는 프레임을 80개 프로세스2에는 20개를 할당해준다. 

### 페이지를 교체하는 방식에 전역 교체, 지역 교체에 대해 설명해 주세요.

페이지를 **교**체하는 방식에는 전역 교체와 지역 교체로 두 가지의 방식이 존재한다. 전역 교체는 메모리상의 모든 프로세스 페이지에 대해 교체를 하는 방식이고 지역 교체는 메모리상의 자기 프로세스 페이지에서만 교체를 하는 방식이다. 다중 프로그래밍의 경우 메인 메모리에 다양한 프로세스가 동시에 올라올 수 있는데 따라서 다양한 프로세스의 페이지가 메모리에 존재하게 된다. 페이지를 교체할 때 앞의 다양한 알고리즘에 의해 victim page를 선정하게 되는데 선정하는 기준이 전체를 기준으로 하느냐 자기 프로세스의 페이지를 기준으로 하느냐에 대한 차이다. 실제로 전체를 기준으로 페이지를 교체하는 것이 더 효율적이라고 할 수 있다. 

하지만 전역 교체의 경우 한 가지 문제점이 있다. 프로세스의 메모리에 있는 페이지 집합이 해당 프로세스의 페이징 동작뿐만 아니라 다른 프로세스의 페이징 동작에도 영향을 받는다. 예를 들면, 어떨 때는 0.5초 걸리던 것이 다음 실행 때는 10초가 걸리 수 도 있다. 지역 교체 방법에서는 이런 현상이 발생하지 않는다.

### **스레싱(Thrashing)**

반복적으로 페이지 폴트가 발생해서, 과도하게 페이지 교체 작업이 일어나, 실제로는 아무일도 하지 못하는 상황
## 이미르
